{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Analysis Rater Influence - EmpkinS Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import biopsykit as bp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from fau_colors import cmaps, register_fausans_font\n",
    "\n",
    "from pepbench.annotations import load_annotations_from_dataset\n",
    "from pepbench.annotations.stats import add_annotation_agreement_to_results_dataframe\n",
    "from pepbench.data_handling import (\n",
    "    compute_pep_performance_metrics,\n",
    "    merge_result_metrics_from_multiple_annotators,\n",
    "    merge_results_per_sample_from_different_annotators,\n",
    ")\n",
    "from pepbench.datasets import EmpkinsDataset, GuardianDataset\n",
    "from pepbench.export import (\n",
    "    convert_to_latex,\n",
    ")\n",
    "from pepbench.io import load_challenge_results_from_folder\n",
    "from pepbench.utils import rename_algorithms, rename_metrics\n",
    "\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_fausans_font()\n",
    "plt.close(\"all\")\n",
    "\n",
    "palette = sns.color_palette(cmaps.faculties_light)\n",
    "sns.set_theme(context=\"notebook\", style=\"ticks\", font=\"sans-serif\", palette=palette)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42\n",
    "plt.rcParams[\"mathtext.default\"] = \"regular\"\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams[\"font.sans-serif\"] = \"FAUSans Office\"\n",
    "\n",
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_type = \"local\"\n",
    "\n",
    "config_dict = json.load(root_path.joinpath(\"config.json\").open(encoding=\"utf-8\"))\n",
    "\n",
    "empkins_base_path = Path(config_dict[deploy_type][\"empkins_path\"])\n",
    "guardian_base_path = Path(config_dict[deploy_type][\"guardian_path\"])\n",
    "print(empkins_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = root_path.joinpath(\"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_path = json.load(root_path.joinpath(\"paper_path.json\").open(encoding=\"utf-8\"))[\"paper_path\"]\n",
    "paper_path = Path(paper_path)\n",
    "\n",
    "export_path = root_path.joinpath(\"exports\")\n",
    "img_path = export_path.joinpath(\"plots\")\n",
    "stats_path = export_path.joinpath(\"stats\")\n",
    "\n",
    "img_path_paper = paper_path.joinpath(\"img\")\n",
    "tab_path_paper = paper_path.joinpath(\"tab\")\n",
    "suppl_img_path_paper = paper_path.joinpath(\"supplementary_material/img\")\n",
    "suppl_tab_path_paper = paper_path.joinpath(\"supplementary_material/tab\")\n",
    "\n",
    "bp.utils.file_handling.mkdirs(\n",
    "    [\n",
    "        result_path,\n",
    "        export_path,\n",
    "        img_path,\n",
    "        stats_path,\n",
    "        img_path_paper,\n",
    "        tab_path_paper,\n",
    "        suppl_img_path_paper,\n",
    "        suppl_tab_path_paper,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EmpkinS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_empkins_01 = EmpkinsDataset(empkins_base_path, use_cache=True, only_labeled=True, label_type=\"rater_01\")\n",
    "dataset_empkins_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_empkins_02 = EmpkinsDataset(empkins_base_path, use_cache=True, only_labeled=True, label_type=\"rater_02\")\n",
    "dataset_empkins_02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q-Peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_q_peak_empkins_01 = load_challenge_results_from_folder(\n",
    "    result_path.joinpath(\"empkins_dataset_q_peak/rater_01\"),\n",
    "    index_cols_per_sample=[\"participant\", \"condition\", \"phase\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_q_peak_empkins_02 = load_challenge_results_from_folder(\n",
    "    result_path.joinpath(\"empkins_dataset_q_peak/rater_02\"),\n",
    "    index_cols_per_sample=[\"participant\", \"condition\", \"phase\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_per_sample_q_peak_empkins_01 = results_q_peak_empkins_01.per_sample.droplevel([1, 2])\n",
    "results_agg_total_q_peak_empkins_01 = results_q_peak_empkins_01.agg_total.droplevel([1, 2])\n",
    "\n",
    "results_per_sample_q_peak_empkins_02 = results_q_peak_empkins_02.per_sample.droplevel([1, 2])\n",
    "results_agg_total_q_peak_empkins_02 = results_q_peak_empkins_02.agg_total.droplevel([1, 2])\n",
    "\n",
    "results_per_sample_q_peak_empkins_02.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B-Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_b_point_empkins_01 = load_challenge_results_from_folder(\n",
    "    result_path.joinpath(\"empkins_dataset_b_point/rater_01\"),\n",
    "    index_cols_per_sample=[\"participant\", \"condition\", \"phase\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_b_point_empkins_02 = load_challenge_results_from_folder(\n",
    "    result_path.joinpath(\"empkins_dataset_b_point/rater_02\"),\n",
    "    index_cols_per_sample=[\"participant\", \"condition\", \"phase\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_per_sample_b_point_empkins_01 = results_b_point_empkins_01.per_sample.droplevel([0])\n",
    "results_agg_total_b_point_empkins_01 = results_b_point_empkins_01.agg_total.droplevel([0])\n",
    "\n",
    "results_per_sample_b_point_empkins_02 = results_b_point_empkins_02.per_sample.droplevel([0])\n",
    "results_agg_total_b_point_empkins_02 = results_b_point_empkins_02.agg_total.droplevel([0])\n",
    "results_per_sample_b_point_empkins_02.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pipeline_empkins_01 = load_challenge_results_from_folder(\n",
    "    result_path.joinpath(\"empkins_dataset_both_algorithms/rater_01\"),\n",
    "    index_cols_per_sample=[\"participant\", \"condition\", \"phase\"],\n",
    ")\n",
    "results_pipeline_empkins_02 = load_challenge_results_from_folder(\n",
    "    result_path.joinpath(\"empkins_dataset_both_algorithms/rater_02\"),\n",
    "    index_cols_per_sample=[\"participant\", \"condition\", \"phase\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_per_sample_pipeline_empkins_01 = results_pipeline_empkins_01.per_sample\n",
    "results_agg_total_pipeline_empkins_01 = results_pipeline_empkins_01.agg_total\n",
    "\n",
    "results_per_sample_pipeline_empkins_02 = results_pipeline_empkins_02.per_sample\n",
    "results_agg_total_pipeline_empkins_02 = results_pipeline_empkins_02.agg_total\n",
    "results_per_sample_pipeline_empkins_02.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_empkins = {}\n",
    "result_dict_guardian = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q-Peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_q_peak_empkins_01 = compute_pep_performance_metrics(\n",
    "    results_per_sample_q_peak_empkins_01, num_heartbeats=results_agg_total_q_peak_empkins_01\n",
    ")\n",
    "metrics_q_peak_empkins_02 = compute_pep_performance_metrics(\n",
    "    results_per_sample_q_peak_empkins_02, num_heartbeats=results_agg_total_q_peak_empkins_02\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_q_peak_empkins = merge_result_metrics_from_multiple_annotators(\n",
    "    [metrics_q_peak_empkins_01, metrics_q_peak_empkins_02]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_q_peak_empkins = metrics_q_peak_empkins.rename(index=rename_algorithms).rename(columns=rename_metrics)\n",
    "metrics_q_peak_empkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_annotator_difference_q_peak_empkins = (\n",
    "    metrics_q_peak_empkins[[(\"Annotator Difference\", \"Mean Absolute Error [ms]\", \"Mean\")]].abs().describe().T\n",
    ")\n",
    "result_dict_empkins[\"Annotator_Difference_Q_Peak\"] = mean_annotator_difference_q_peak_empkins\n",
    "mean_annotator_difference_q_peak_empkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_q_peak_empkins_style = metrics_q_peak_empkins.style.background_gradient(\n",
    "    subset=[(\"Annotator 1\", \"Mean Absolute Error [ms]\", \"Mean\"), (\"Annotator 2\", \"Mean Absolute Error [ms]\", \"Mean\")]\n",
    ")\n",
    "latex_output = convert_to_latex(\n",
    "    metrics_q_peak_empkins_style,\n",
    "    collapse_index_columns=False,\n",
    "    column_header_bold=True,\n",
    "    column_format=\"p{3.0cm}\"\n",
    "    + \"S[table-column-width=0.75cm,table-format=2.2]\" * len(metrics_q_peak_empkins_style.columns),\n",
    "    caption=r\"Error metrics of Q-peak extraction algorithms on the \\textit{EmpkinS Dataset} for different annotators and MAE difference between both annotators. MAE = Mean Absolute Error, ME = Mean Error.\",\n",
    "    label=\"tab:q_peak_annotation_differences_empkins\",\n",
    ")\n",
    "latex_output = latex_output.replace(r\"\\bfseries Mean Absolute Error\", r\"\\bfseries MAE\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries Mean Error\", r\"\\bfseries ME\")\n",
    "latex_output = latex_output.replace(r\"\\begin{table}[ht]\", r\"\\begin{table}[ht]\\small\")\n",
    "latex_output = latex_output.replace(r\"q_peak_algorithm\", r\"\\bfseries Q-peak Algorithm\")\n",
    "latex_output = latex_output.replace(r\"\\sisetup{\", r\"\\sisetup{round-mode=places,round-precision=2,\")\n",
    "\n",
    "suppl_tab_path_paper.joinpath(\"tab_q_peak_annotator_difference_empkins.tex\").open(mode=\"w+\").write(latex_output)\n",
    "metrics_q_peak_empkins_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B-Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_b_point_empkins_01 = compute_pep_performance_metrics(\n",
    "    results_per_sample_b_point_empkins_01, num_heartbeats=results_agg_total_b_point_empkins_01\n",
    ")\n",
    "metrics_b_point_empkins_02 = compute_pep_performance_metrics(\n",
    "    results_per_sample_b_point_empkins_02, num_heartbeats=results_agg_total_b_point_empkins_02\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_b_point_empkins = merge_result_metrics_from_multiple_annotators(\n",
    "    [metrics_b_point_empkins_01, metrics_b_point_empkins_02]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_b_point_empkins = metrics_b_point_empkins.rename(index=rename_algorithms).rename(columns=rename_metrics)\n",
    "metrics_b_point_empkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_b_point_empkins[[(\"Annotator Difference\", \"Mean Absolute Error [ms]\", \"Mean\")]].abs().describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_annotator_difference_b_point_empkins = (\n",
    "    metrics_b_point_empkins[[(\"Annotator Difference\", \"Mean Absolute Error [ms]\", \"Mean\")]].abs().describe().T\n",
    ")\n",
    "result_dict_empkins[\"Annotator_Difference_B_Point\"] = mean_annotator_difference_b_point_empkins\n",
    "mean_annotator_difference_b_point_empkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_b_point_empkins_style = metrics_b_point_empkins.style.background_gradient(\n",
    "    subset=[(\"Annotator 1\", \"Mean Absolute Error [ms]\", \"Mean\"), (\"Annotator 2\", \"Mean Absolute Error [ms]\", \"Mean\")]\n",
    ")\n",
    "latex_output = convert_to_latex(\n",
    "    metrics_b_point_empkins_style,\n",
    "    collapse_index_columns=False,\n",
    "    column_header_bold=True,\n",
    "    column_format=\"p{1.5cm}p{1.5cm}\"\n",
    "    + \"S[table-column-width=0.75cm,table-format=2.2]\" * len(metrics_q_peak_empkins_style.columns),\n",
    "    caption=r\"Error metrics of B-point extraction algorithms on the \\textit{EmpkinS Dataset} for different annotators and MAE difference between both annotators. MAE = Mean Absolute Error, ME = Mean Error.\",\n",
    "    label=\"tab:b_point_annotation_differences_empkins\",\n",
    ")\n",
    "latex_output = latex_output.replace(r\"\\bfseries Mean Absolute Error\", r\"\\bfseries MAE\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries Mean Error\", r\"\\bfseries ME\")\n",
    "latex_output = latex_output.replace(r\"\\begin{table}[ht]\", r\"\\begin{table}[ht]\\small\")\n",
    "latex_output = latex_output.replace(r\"b_point_algorithm\", r\"\\bfseries B-point Algorithm\")\n",
    "latex_output = latex_output.replace(r\"outlier_correction_algorithm\", r\"\\bfseries Outlier Correction Algorithm\")\n",
    "latex_output = latex_output.replace(r\"\\sisetup{\", r\"\\sisetup{round-mode=places,round-precision=2,\")\n",
    "\n",
    "suppl_tab_path_paper.joinpath(\"tab_b_point_annotator_difference_empkins.tex\").open(mode=\"w+\").write(latex_output)\n",
    "metrics_b_point_empkins_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_pipeline_empkins_01 = compute_pep_performance_metrics(\n",
    "    results_per_sample_pipeline_empkins_01, num_heartbeats=results_agg_total_pipeline_empkins_01\n",
    ")\n",
    "metrics_pipeline_empkins_02 = compute_pep_performance_metrics(\n",
    "    results_per_sample_pipeline_empkins_02, num_heartbeats=results_agg_total_pipeline_empkins_02\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_pipeline_empkins = merge_result_metrics_from_multiple_annotators(\n",
    "    [metrics_pipeline_empkins_01, metrics_pipeline_empkins_02]\n",
    ")\n",
    "metrics_pipeline_empkins = metrics_pipeline_empkins.rename(index=rename_algorithms).rename(columns=rename_metrics)\n",
    "metrics_pipeline_empkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_annotator_difference_pipeline_empkins = (\n",
    "    metrics_pipeline_empkins[[(\"Annotator Difference\", \"Mean Absolute Error [ms]\", \"Mean\")]].abs().describe().T\n",
    ")\n",
    "result_dict_empkins[\"Annotator_Difference_Pipeline\"] = mean_annotator_difference_pipeline_empkins\n",
    "mean_annotator_difference_pipeline_empkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_pipeline_empkins_style = metrics_pipeline_empkins.style.background_gradient(\n",
    "    subset=[(\"Annotator 1\", \"Mean Absolute Error [ms]\", \"Mean\"), (\"Annotator 2\", \"Mean Absolute Error [ms]\", \"Mean\")]\n",
    ").format(precision=2)\n",
    "latex_output = convert_to_latex(\n",
    "    metrics_pipeline_empkins_style,\n",
    "    collapse_index_columns=False,\n",
    "    column_header_bold=True,\n",
    "    environment=\"longtable\",\n",
    "    column_format=\"p{1.15cm}p{1.25cm}p{1.25cm}\"\n",
    "    + \"S[table-column-width=0.75cm,table-format=1.1(2)]\" * len(metrics_pipeline_empkins_style.columns),\n",
    "    caption=r\"Error metrics of PEP extraction pipelines on the \\textit{EmpkinS Dataset} for different annotators and MAE difference between both annotators. MAE = Mean Absolute Error, ME = Mean Error.\",\n",
    "    label=\"tab:pipeline_annotation_differences_empkins\",\n",
    ")\n",
    "latex_output = latex_output.replace(r\"\\begin{longtable}\", r\"\\begin{small}\\begin{longtable}\")\n",
    "latex_output = latex_output.replace(r\"\\end{longtable}\", r\"\\end{longtable}\\end{small}\")\n",
    "latex_output = latex_output.replace(r\"\\font-weightbold \", r\"\\bfseries \")\n",
    "# latex_output = latex_output.replace(r\"Van13 \", r\"Van13\\,\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries Mean Absolute Error\", r\"\\bfseries MAE\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries Mean Error\", r\"\\bfseries ME\")\n",
    "latex_output = latex_output.replace(r\"q_peak_algorithm\", r\"\\bfseries Q-peak Algorithm\")\n",
    "latex_output = latex_output.replace(r\"b_point_algorithm\", r\"\\bfseries B-point Algorithm\")\n",
    "latex_output = latex_output.replace(r\"outlier_correction_algorithm\", r\"\\bfseries Outlier Correction Algorithm\")\n",
    "latex_output = latex_output.replace(r\"Annotator Difference\", r\"\\bfseries Ann. Diff.\")\n",
    "latex_output = re.sub(\n",
    "    r\"(\\\\multirow\\[c\\]\\{\\d+\\}\\{\\*\\})\\{(Van13\\s*\\(\\d+\\s*ms\\))\\}\", r\"\\1{\\\\parbox{1.25cm}{\\2}}\", latex_output\n",
    ")\n",
    "\n",
    "suppl_tab_path_paper.joinpath(\"tab_pep_pipeline_annotator_difference_empkins.tex\").open(mode=\"w+\").write(latex_output)\n",
    "metrics_pipeline_empkins_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison between different Agreement Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_empkins = load_annotations_from_dataset(dataset_empkins_01, dataset_empkins_02)\n",
    "\n",
    "annotations_ecg_empkins = annotations_empkins.xs(\"ECG\", level=\"signal\")\n",
    "annotations_icg_empkins = annotations_empkins.xs(\"ICG\", level=\"signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_q_peak_algorithm = \"martinez2004\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_q_peak_empkins = merge_results_per_sample_from_different_annotators(\n",
    "    [results_per_sample_q_peak_empkins_01, results_per_sample_q_peak_empkins_02],\n",
    "    selected_algorithm=selected_q_peak_algorithm,\n",
    ")\n",
    "results_q_peak_empkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_b_point_algorithm = (\"drost2022\", \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_b_point_empkins = merge_results_per_sample_from_different_annotators(\n",
    "    [results_per_sample_b_point_empkins_01, results_per_sample_b_point_empkins_02],\n",
    "    selected_algorithm=selected_b_point_algorithm,\n",
    ")\n",
    "results_b_point_empkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pipeline = (\"forouzanfar2018\", \"drost2022\", \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pipeline_empkins = merge_results_per_sample_from_different_annotators(\n",
    "    [results_per_sample_pipeline_empkins_01, results_per_sample_pipeline_empkins_02],\n",
    "    selected_algorithm=selected_pipeline,\n",
    ")\n",
    "results_pipeline_empkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_q_peak_agreement_bins_empkins = add_annotation_agreement_to_results_dataframe(\n",
    "    results_q_peak_empkins, annotations_ecg_empkins, dataset_empkins_01.sampling_rate_ecg\n",
    ")\n",
    "results_q_peak_agreement_bins_empkins = results_q_peak_agreement_bins_empkins.groupby(\n",
    "    \"agreement_bins\", observed=True\n",
    ").agg([\"mean\", \"std\"])\n",
    "result_dict_empkins[\"Annotation_Agreement_Q_Peak\"] = results_q_peak_agreement_bins_empkins\n",
    "\n",
    "results_q_peak_agreement_bins_empkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_output = convert_to_latex(\n",
    "    results_q_peak_agreement_bins_empkins.droplevel([1, 2], axis=1),\n",
    "    collapse_index_columns=False,\n",
    "    column_header_bold=True,\n",
    "    column_format=\"p{2.0cm}\"\n",
    "    + \"S[table-column-width=0.75cm,table-format=2.2]\" * len(results_q_peak_agreement_bins_empkins.columns),\n",
    "    caption=r\"Effect of annotation agreement on the absolute error (AE) of selected Q-peak extraction algorithm (Mar04) on the \\textit{EmpkinS Dataset}. Annotation agreements: \\textit{high}: [0\\,ms, 4\\,ms], \\textit{medium}: [5\\,ms, 10\\,ms], \\textit{low}: $\\geq$ 11\\,ms\",\n",
    "    label=\"tab:q_peak_annotation_agreement_empkins\",\n",
    ")\n",
    "\n",
    "latex_output = latex_output.replace(\"agreement_bins\", \"Agreement Bins\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries mean\", r\"\\bfseries Mean\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries std\", r\"\\bfseries SD\")\n",
    "latex_output = latex_output.replace(r\"\\sisetup{\", r\"\\sisetup{round-mode=places,round-precision=2,\")\n",
    "\n",
    "suppl_tab_path_paper.joinpath(\"tab_q_peak_annotation_agreement_empkins.tex\").open(mode=\"w+\").write(latex_output)\n",
    "\n",
    "print(latex_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_b_point_agreement_bins_empkins = add_annotation_agreement_to_results_dataframe(\n",
    "    results_b_point_empkins, annotations_icg_empkins, dataset_empkins_01.sampling_rate_icg\n",
    ")\n",
    "results_b_point_agreement_bins_empkins = results_b_point_agreement_bins_empkins.groupby(\n",
    "    \"agreement_bins\", observed=True\n",
    ").agg([\"mean\", \"std\"])\n",
    "result_dict_empkins[\"Annotation_Agreement_B_Point\"] = results_b_point_agreement_bins_empkins\n",
    "\n",
    "results_b_point_agreement_bins_empkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_output = convert_to_latex(\n",
    "    results_b_point_agreement_bins_empkins.droplevel([1, 2], axis=1),\n",
    "    collapse_index_columns=False,\n",
    "    column_header_bold=True,\n",
    "    column_format=\"p{2.0cm}\"\n",
    "    + \"S[table-column-width=0.75cm,table-format=2.2]\" * len(results_q_peak_agreement_bins_empkins.columns),\n",
    "    caption=r\"Effect of annotation agreement on the absolute error (AE) of selected B-point extraction algorithm (Dro22) on the \\textit{EmpkinS Dataset}. Annotation agreements: \\textit{high}: [0\\,ms, 4\\,ms], \\textit{medium}: [5\\,ms, 10\\,ms], \\textit{low}: $\\geq$ 11\\,ms.\",\n",
    "    label=\"tab:b_point_annotation_agreement_empkins\",\n",
    ")\n",
    "\n",
    "latex_output = latex_output.replace(\"agreement_bins\", \"Agreement Bins\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries mean\", r\"\\bfseries Mean\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries std\", r\"\\bfseries SD\")\n",
    "latex_output = latex_output.replace(r\"\\sisetup{\", r\"\\sisetup{round-mode=places,round-precision=2,\")\n",
    "\n",
    "suppl_tab_path_paper.joinpath(\"tab_b_point_annotation_agreement_empkins.tex\").open(mode=\"w+\").write(latex_output)\n",
    "\n",
    "print(latex_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pipeline_q_peak_agreement_bins_empkins = add_annotation_agreement_to_results_dataframe(\n",
    "    results_pipeline_empkins, annotations_ecg_empkins, dataset_empkins_01.sampling_rate_icg\n",
    ")\n",
    "results_pipeline_q_peak_agreement_bins_empkins = results_pipeline_q_peak_agreement_bins_empkins.groupby(\n",
    "    \"agreement_bins\", observed=True\n",
    ").agg([\"mean\", \"std\"])\n",
    "result_dict_empkins[\"Annotation_Agreement_Pipeline_Q_Peak\"] = results_pipeline_q_peak_agreement_bins_empkins\n",
    "\n",
    "results_pipeline_q_peak_agreement_bins_empkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_output = convert_to_latex(\n",
    "    results_pipeline_q_peak_agreement_bins_empkins.droplevel([1, 2], axis=1),\n",
    "    collapse_index_columns=False,\n",
    "    column_header_bold=True,\n",
    "    column_format=\"p{2.0cm}\"\n",
    "    + \"S[table-column-width=0.75cm,table-format=2.2]\" * len(results_q_peak_agreement_bins_empkins.columns),\n",
    "    caption=r\"Effect of annotation agreement on the absolute error (AE) of selected PEP pipeline [For18, Dro22, None] on the \\textit{EmpkinS Dataset}, using Q-peak annotations for agreement computation. Annotation agreements: \\textit{high}: [0\\,ms, 4\\,ms], \\textit{medium}: [5\\,ms, 10\\,ms], \\textit{low}: $\\geq$ 11\\,ms.\",\n",
    "    label=\"tab:pipeline_q_peak_annotation_agreement_empkins\",\n",
    ")\n",
    "\n",
    "latex_output = latex_output.replace(\"agreement_bins\", \"Agreement Bins\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries mean\", r\"\\bfseries Mean\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries std\", r\"\\bfseries SD\")\n",
    "latex_output = latex_output.replace(r\"\\sisetup{\", r\"\\sisetup{round-mode=places,round-precision=2,\")\n",
    "\n",
    "suppl_tab_path_paper.joinpath(\"tab_pep_pipeline_q_peak_annotation_agreement_empkins.tex\").open(mode=\"w+\").write(\n",
    "    latex_output\n",
    ")\n",
    "\n",
    "print(latex_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pipeline_b_point_agreement_bins_empkins = add_annotation_agreement_to_results_dataframe(\n",
    "    results_pipeline_empkins, annotations_icg_empkins, dataset_empkins_01.sampling_rate_icg\n",
    ")\n",
    "results_pipeline_b_point_agreement_bins_empkins = results_pipeline_b_point_agreement_bins_empkins.groupby(\n",
    "    \"agreement_bins\", observed=True\n",
    ").agg([\"mean\", \"std\"])\n",
    "result_dict_empkins[\"Annotation_Agreement_Pipeline_B_Point\"] = results_pipeline_b_point_agreement_bins_empkins\n",
    "\n",
    "results_pipeline_b_point_agreement_bins_empkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_output = convert_to_latex(\n",
    "    results_pipeline_b_point_agreement_bins_empkins.droplevel([1, 2], axis=1),\n",
    "    collapse_index_columns=False,\n",
    "    column_header_bold=True,\n",
    "    column_format=\"p{2.0cm}\"\n",
    "    + \"S[table-column-width=0.75cm,table-format=2.2]\" * len(results_q_peak_agreement_bins_empkins.columns),\n",
    "    caption=r\"Effect of annotation agreement on the absolute error (AE) of selected PEP pipeline [For18, Dro22, None] on the \\textit{EmpkinS Dataset}, using B-point annotations for agreement computation. Annotation agreements: \\textit{high}: [0\\,ms, 4\\,ms], \\textit{medium}: [5\\,ms, 10\\,ms], \\textit{low}: $\\geq$ 11\\,ms.\",\n",
    "    label=\"tab:pipeline_b_point_annotation_agreement_empkins\",\n",
    ")\n",
    "\n",
    "latex_output = latex_output.replace(\"agreement_bins\", \"Agreement Bins\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries mean\", r\"\\bfseries Mean\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries std\", r\"\\bfseries SD\")\n",
    "latex_output = latex_output.replace(r\"\\sisetup{\", r\"\\sisetup{round-mode=places,round-precision=2,\")\n",
    "\n",
    "\n",
    "suppl_tab_path_paper.joinpath(\"tab_pep_pipeline_b_point_annotation_agreement_empkins.tex\").open(mode=\"w+\").write(\n",
    "    latex_output\n",
    ")\n",
    "\n",
    "print(latex_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardian Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_guardian_01 = GuardianDataset(guardian_base_path, use_cache=True, only_labeled=True, label_type=\"rater_01\")\n",
    "dataset_guardian_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_guardian_02 = GuardianDataset(guardian_base_path, use_cache=True, only_labeled=True, label_type=\"rater_02\")\n",
    "dataset_guardian_02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q-Peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_q_peak_guardian_01 = load_challenge_results_from_folder(\n",
    "    result_path.joinpath(\"guardian_dataset_q_peak/rater_01\"),\n",
    "    index_cols_per_sample=[\"participant\", \"phase\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_q_peak_guardian_02 = load_challenge_results_from_folder(\n",
    "    result_path.joinpath(\"guardian_dataset_q_peak/rater_02\"),\n",
    "    index_cols_per_sample=[\"participant\", \"phase\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_per_sample_q_peak_guardian_01 = results_q_peak_guardian_01.per_sample.droplevel([1, 2])\n",
    "results_agg_total_q_peak_guardian_01 = results_q_peak_guardian_01.agg_total.droplevel([1, 2])\n",
    "\n",
    "results_per_sample_q_peak_guardian_02 = results_q_peak_guardian_02.per_sample.droplevel([1, 2])\n",
    "results_agg_total_q_peak_guardian_02 = results_q_peak_guardian_02.agg_total.droplevel([1, 2])\n",
    "\n",
    "results_per_sample_q_peak_guardian_02.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B-Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_b_point_guardian_01 = load_challenge_results_from_folder(\n",
    "    result_path.joinpath(\"guardian_dataset_b_point/rater_01\"),\n",
    "    index_cols_per_sample=[\"participant\", \"phase\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_b_point_guardian_02 = load_challenge_results_from_folder(\n",
    "    result_path.joinpath(\"guardian_dataset_b_point/rater_02\"),\n",
    "    index_cols_per_sample=[\"participant\", \"phase\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_per_sample_b_point_guardian_01 = results_b_point_guardian_01.per_sample.droplevel([0])\n",
    "results_agg_total_b_point_guardian_01 = results_b_point_guardian_01.agg_total.droplevel([0])\n",
    "\n",
    "results_per_sample_b_point_guardian_02 = results_b_point_guardian_02.per_sample.droplevel([0])\n",
    "results_agg_total_b_point_guardian_02 = results_b_point_guardian_02.agg_total.droplevel([0])\n",
    "results_per_sample_b_point_guardian_02.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pipeline_guardian_01 = load_challenge_results_from_folder(\n",
    "    result_path.joinpath(\"guardian_dataset_both_algorithms/rater_01\"),\n",
    "    index_cols_per_sample=[\"participant\", \"phase\"],\n",
    ")\n",
    "results_pipeline_guardian_02 = load_challenge_results_from_folder(\n",
    "    result_path.joinpath(\"guardian_dataset_both_algorithms/rater_02\"),\n",
    "    index_cols_per_sample=[\"participant\", \"phase\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_per_sample_pipeline_guardian_01 = results_pipeline_guardian_01.per_sample\n",
    "results_agg_total_pipeline_guardian_01 = results_pipeline_guardian_01.agg_total\n",
    "\n",
    "results_per_sample_pipeline_guardian_02 = results_pipeline_guardian_02.per_sample\n",
    "results_agg_total_pipeline_guardian_02 = results_pipeline_guardian_02.agg_total\n",
    "results_per_sample_pipeline_guardian_02.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q-Peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_q_peak_guardian_01 = compute_pep_performance_metrics(\n",
    "    results_per_sample_q_peak_guardian_01, num_heartbeats=results_agg_total_q_peak_guardian_01\n",
    ")\n",
    "metrics_q_peak_guardian_02 = compute_pep_performance_metrics(\n",
    "    results_per_sample_q_peak_guardian_02, num_heartbeats=results_agg_total_q_peak_guardian_02\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_q_peak_guardian = merge_result_metrics_from_multiple_annotators(\n",
    "    [metrics_q_peak_guardian_01, metrics_q_peak_guardian_02]\n",
    ")\n",
    "metrics_q_peak_guardian = metrics_q_peak_guardian.rename(index=rename_algorithms).rename(columns=rename_metrics)\n",
    "metrics_q_peak_guardian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_annotator_difference_q_peak_guardian = (\n",
    "    metrics_q_peak_guardian[[(\"Annotator Difference\", \"Mean Absolute Error [ms]\", \"Mean\")]].abs().describe().T\n",
    ")\n",
    "result_dict_guardian[\"Annotator_Difference_Q_Peak\"] = mean_annotator_difference_q_peak_guardian\n",
    "mean_annotator_difference_q_peak_guardian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_q_peak_guardian_style = metrics_q_peak_guardian.style.background_gradient(\n",
    "    subset=[(\"Annotator 1\", \"Mean Absolute Error [ms]\", \"Mean\"), (\"Annotator 2\", \"Mean Absolute Error [ms]\", \"Mean\")]\n",
    ")\n",
    "latex_output = convert_to_latex(\n",
    "    metrics_q_peak_guardian_style,\n",
    "    collapse_index_columns=False,\n",
    "    column_header_bold=True,\n",
    "    column_format=\"p{3.0cm}\"\n",
    "    + \"S[table-column-width=0.75cm,table-format=2.2]\" * len(metrics_q_peak_guardian_style.columns),\n",
    "    caption=r\"Error metrics of Q-peak extraction algorithms on the \\textit{Guardian Dataset} for different annotators and MAE difference between both annotators. MAE = Mean Absolute Error, ME = Mean Error.\",\n",
    "    label=\"tab:q_peak_annotation_differences_guardian\",\n",
    ")\n",
    "latex_output = latex_output.replace(r\"\\bfseries Mean Absolute Error\", r\"\\bfseries MAE\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries Mean Error\", r\"\\bfseries ME\")\n",
    "latex_output = latex_output.replace(r\"\\begin{table}[ht]\", r\"\\begin{table}[ht]\\small\")\n",
    "latex_output = latex_output.replace(r\"q_peak_algorithm\", r\"\\bfseries Q-peak Algorithm\")\n",
    "latex_output = latex_output.replace(r\"\\sisetup{\", r\"\\sisetup{round-mode=places,round-precision=2,\")\n",
    "\n",
    "suppl_tab_path_paper.joinpath(\"tab_q_peak_annotator_difference_guardian.tex\").open(mode=\"w+\").write(latex_output)\n",
    "metrics_q_peak_guardian_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B-Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_b_point_guardian_01 = compute_pep_performance_metrics(\n",
    "    results_per_sample_b_point_guardian_01, num_heartbeats=results_agg_total_b_point_guardian_01\n",
    ")\n",
    "metrics_b_point_guardian_02 = compute_pep_performance_metrics(\n",
    "    results_per_sample_b_point_guardian_02, num_heartbeats=results_agg_total_b_point_guardian_02\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_b_point_guardian = merge_result_metrics_from_multiple_annotators(\n",
    "    [metrics_b_point_guardian_01, metrics_b_point_guardian_02]\n",
    ")\n",
    "metrics_b_point_guardian = metrics_b_point_guardian.rename(index=rename_algorithms).rename(columns=rename_metrics)\n",
    "metrics_b_point_guardian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_annotator_difference_b_point_guardian = (\n",
    "    metrics_b_point_guardian[[(\"Annotator Difference\", \"Mean Absolute Error [ms]\", \"Mean\")]].abs().describe().T\n",
    ")\n",
    "result_dict_guardian[\"Annotator_Difference_B_Point\"] = mean_annotator_difference_b_point_guardian\n",
    "mean_annotator_difference_b_point_guardian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_b_point_guardian_style = metrics_b_point_guardian.style.background_gradient(\n",
    "    subset=[(\"Annotator 1\", \"Mean Absolute Error [ms]\", \"Mean\"), (\"Annotator 2\", \"Mean Absolute Error [ms]\", \"Mean\")]\n",
    ")\n",
    "latex_output = convert_to_latex(\n",
    "    metrics_b_point_guardian_style,\n",
    "    collapse_index_columns=False,\n",
    "    column_header_bold=True,\n",
    "    column_format=\"p{1.5cm}p{1.5cm}\"\n",
    "    + \"S[table-column-width=0.75cm,table-format=2.2]\" * len(metrics_q_peak_guardian_style.columns),\n",
    "    caption=r\"Error metrics of B-point extraction algorithms on the \\textit{Guardian Dataset} for different annotators and MAE difference between both annotators. MAE = Mean Absolute Error, ME = Mean Error.\",\n",
    "    label=\"tab:b_point_annotation_differences_guardian\",\n",
    ")\n",
    "latex_output = latex_output.replace(r\"\\bfseries Mean Absolute Error\", r\"\\bfseries MAE\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries Mean Error\", r\"\\bfseries ME\")\n",
    "latex_output = latex_output.replace(r\"\\begin{table}[ht]\", r\"\\begin{table}[ht]\\small\")\n",
    "latex_output = latex_output.replace(r\"b_point_algorithm\", r\"\\bfseries B-point Algorithm\")\n",
    "latex_output = latex_output.replace(r\"outlier_correction_algorithm\", r\"\\bfseries Outlier Correction Algorithm\")\n",
    "latex_output = latex_output.replace(r\"\\sisetup{\", r\"\\sisetup{round-mode=places,round-precision=2,\")\n",
    "\n",
    "suppl_tab_path_paper.joinpath(\"tab_b_point_annotator_difference_guardian.tex\").open(mode=\"w+\").write(latex_output)\n",
    "metrics_b_point_guardian_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_pipeline_guardian_01 = compute_pep_performance_metrics(\n",
    "    results_per_sample_pipeline_guardian_01, num_heartbeats=results_agg_total_pipeline_guardian_01\n",
    ")\n",
    "metrics_pipeline_guardian_02 = compute_pep_performance_metrics(\n",
    "    results_per_sample_pipeline_guardian_02, num_heartbeats=results_agg_total_pipeline_guardian_02\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_pipeline_guardian = merge_result_metrics_from_multiple_annotators(\n",
    "    [metrics_pipeline_guardian_01, metrics_pipeline_guardian_02]\n",
    ")\n",
    "metrics_pipeline_guardian = metrics_pipeline_guardian.rename(index=rename_algorithms).rename(columns=rename_metrics)\n",
    "metrics_pipeline_guardian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_annotator_difference_pipeline_guardian = (\n",
    "    metrics_pipeline_guardian[[(\"Annotator Difference\", \"Mean Absolute Error [ms]\", \"Mean\")]].abs().describe().T\n",
    ")\n",
    "result_dict_guardian[\"Annotator_Difference_Pipeline\"] = mean_annotator_difference_pipeline_guardian\n",
    "mean_annotator_difference_pipeline_guardian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_pipeline_guardian_style = metrics_pipeline_guardian.style.background_gradient(\n",
    "    subset=[(\"Annotator 1\", \"Mean Absolute Error [ms]\", \"Mean\"), (\"Annotator 2\", \"Mean Absolute Error [ms]\", \"Mean\")]\n",
    ").format(precision=2)\n",
    "latex_output = convert_to_latex(\n",
    "    metrics_pipeline_guardian_style,\n",
    "    collapse_index_columns=False,\n",
    "    column_header_bold=True,\n",
    "    environment=\"longtable\",\n",
    "    column_format=\"p{1.25cm}p{1.25cm}p{1.25cm}\"\n",
    "    + \"S[table-column-width=0.75cm,table-format=1.1(2)]\" * len(metrics_pipeline_guardian_style.columns),\n",
    "    caption=r\"Error metrics of PEP extraction pipelines on the \\textit{Guardian Dataset} for different annotators and MAE difference between both annotators. MAE = Mean Absolute Error, ME = Mean Error.\",\n",
    "    label=\"tab:pipeline_annotation_differences_guardian\",\n",
    ")\n",
    "latex_output = latex_output.replace(r\"\\begin{longtable}\", r\"\\begin{small}\\begin{longtable}\")\n",
    "latex_output = latex_output.replace(r\"\\end{longtable}\", r\"\\end{longtable}\\end{small}\")\n",
    "latex_output = latex_output.replace(r\"\\font-weightbold \", r\"\\bfseries \")\n",
    "# latex_output = latex_output.replace(r\"Van13 \", r\"Van13\\,\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries Mean Absolute Error\", r\"\\bfseries MAE\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries Mean Error\", r\"\\bfseries ME\")\n",
    "latex_output = latex_output.replace(r\"q_peak_algorithm\", r\"\\bfseries Q-peak Algorithm\")\n",
    "latex_output = latex_output.replace(r\"b_point_algorithm\", r\"\\bfseries B-point Algorithm\")\n",
    "latex_output = latex_output.replace(r\"outlier_correction_algorithm\", r\"\\bfseries Outlier Correction Algorithm\")\n",
    "latex_output = latex_output.replace(r\"Annotator Difference\", r\"\\bfseries Ann. Diff.\")\n",
    "latex_output = re.sub(\n",
    "    r\"(\\\\multirow\\[c\\]\\{\\d+\\}\\{\\*\\})\\{(Van13\\s*\\(\\d+\\s*ms\\))\\}\", r\"\\1{\\\\parbox{1.25cm}{\\2}}\", latex_output\n",
    ")\n",
    "\n",
    "suppl_tab_path_paper.joinpath(\"tab_pep_pipeline_annotator_difference_guardian.tex\").open(mode=\"w+\").write(latex_output)\n",
    "metrics_pipeline_guardian_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison between different Agreement Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_q_peak_algorithm = \"martinez2004\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_q_peak_guardian = merge_results_per_sample_from_different_annotators(\n",
    "    [results_per_sample_q_peak_guardian_01, results_per_sample_q_peak_guardian_02],\n",
    "    selected_algorithm=selected_q_peak_algorithm,\n",
    ")\n",
    "results_q_peak_guardian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_b_point_algorithm = (\"drost2022\", \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_b_point_guardian = merge_results_per_sample_from_different_annotators(\n",
    "    [results_per_sample_b_point_guardian_01, results_per_sample_b_point_guardian_02],\n",
    "    selected_algorithm=selected_b_point_algorithm,\n",
    ")\n",
    "results_b_point_guardian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pipeline = (\"forouzanfar2018\", \"drost2022\", \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pipeline_guardian = merge_results_per_sample_from_different_annotators(\n",
    "    [results_per_sample_pipeline_guardian_01, results_per_sample_pipeline_guardian_02],\n",
    "    selected_algorithm=selected_pipeline,\n",
    ")\n",
    "results_pipeline_guardian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_guardian = load_annotations_from_dataset(dataset_guardian_01, dataset_guardian_02)\n",
    "\n",
    "annotations_ecg_guardian = annotations_guardian.xs(\"ECG\", level=\"signal\")\n",
    "annotations_icg_guardian = annotations_guardian.xs(\"ICG\", level=\"signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_q_peak_agreement_bins_guardian = add_annotation_agreement_to_results_dataframe(\n",
    "    results_q_peak_guardian, annotations_ecg_guardian, dataset_guardian_01.sampling_rate_ecg\n",
    ")\n",
    "results_q_peak_agreement_bins_guardian = results_q_peak_agreement_bins_guardian.groupby(\n",
    "    \"agreement_bins\", observed=True\n",
    ").agg([\"mean\", \"std\"])\n",
    "result_dict_guardian[\"Annotation_Agreement_Q_Peak\"] = results_q_peak_agreement_bins_guardian\n",
    "\n",
    "results_q_peak_agreement_bins_guardian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_output = convert_to_latex(\n",
    "    results_q_peak_agreement_bins_guardian.droplevel([1, 2], axis=1),\n",
    "    collapse_index_columns=False,\n",
    "    column_header_bold=True,\n",
    "    column_format=\"p{2.0cm}\"\n",
    "    + \"S[table-column-width=0.75cm,table-format=2.2]\" * len(results_q_peak_agreement_bins_guardian.columns),\n",
    "    caption=r\"Effect of annotation agreement on the absolute error (AE) of selected Q-peak extraction algorithm (Mar04) on the \\textit{Guardian Dataset}. Annotation agreements: \\textit{high}: [0\\,ms, 4\\,ms], \\textit{medium}: [5\\,ms, 10\\,ms], \\textit{low}: $\\geq$ 11\\,ms\",\n",
    "    label=\"tab:q_peak_annotation_agreement_guardian\",\n",
    ")\n",
    "\n",
    "latex_output = latex_output.replace(\"agreement_bins\", \"Agreement Bins\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries mean\", r\"\\bfseries Mean\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries std\", r\"\\bfseries SD\")\n",
    "latex_output = latex_output.replace(r\"\\sisetup{\", r\"\\sisetup{round-mode=places,round-precision=2,\")\n",
    "\n",
    "suppl_tab_path_paper.joinpath(\"tab_q_peak_annotation_agreement_guardian.tex\").open(mode=\"w+\").write(latex_output)\n",
    "\n",
    "print(latex_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_b_point_agreement_bins_guardian = add_annotation_agreement_to_results_dataframe(\n",
    "    results_b_point_guardian, annotations_icg_guardian, dataset_guardian_01.sampling_rate_icg\n",
    ")\n",
    "results_b_point_agreement_bins_guardian = results_b_point_agreement_bins_guardian.groupby(\n",
    "    \"agreement_bins\", observed=True\n",
    ").agg([\"mean\", \"std\"])\n",
    "result_dict_guardian[\"Annotation_Agreement_B_Point\"] = results_b_point_agreement_bins_guardian\n",
    "\n",
    "results_b_point_agreement_bins_guardian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_output = convert_to_latex(\n",
    "    results_b_point_agreement_bins_guardian.droplevel([1, 2], axis=1),\n",
    "    collapse_index_columns=False,\n",
    "    column_header_bold=True,\n",
    "    column_format=\"p{2.0cm}\"\n",
    "    + \"S[table-column-width=0.75cm,table-format=2.2]\" * len(results_q_peak_agreement_bins_guardian.columns),\n",
    "    caption=r\"Effect of annotation agreement on the absolute error (AE) of selected B-point extraction algorithm (Dro22) on the \\textit{Guardian Dataset}. Annotation agreements: \\textit{high}: [0\\,ms, 4\\,ms], \\textit{medium}: [5\\,ms, 10\\,ms], \\textit{low}: $\\geq$ 11\\,ms.\",\n",
    "    label=\"tab:b_point_annotation_agreement_guardian\",\n",
    ")\n",
    "\n",
    "latex_output = latex_output.replace(\"agreement_bins\", \"Agreement Bins\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries mean\", r\"\\bfseries Mean\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries std\", r\"\\bfseries SD\")\n",
    "latex_output = latex_output.replace(r\"\\sisetup{\", r\"\\sisetup{round-mode=places,round-precision=2,\")\n",
    "\n",
    "suppl_tab_path_paper.joinpath(\"tab_b_point_annotation_agreement_guardian.tex\").open(mode=\"w+\").write(latex_output)\n",
    "\n",
    "print(latex_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pipeline_q_peak_agreement_bins_guardian = add_annotation_agreement_to_results_dataframe(\n",
    "    results_pipeline_guardian, annotations_ecg_guardian, dataset_guardian_01.sampling_rate_icg\n",
    ")\n",
    "results_pipeline_q_peak_agreement_bins_guardian = results_pipeline_q_peak_agreement_bins_guardian.groupby(\n",
    "    \"agreement_bins\", observed=True\n",
    ").agg([\"mean\", \"std\"])\n",
    "result_dict_guardian[\"Annotation_Agreement_Pipeline_Q_Peak\"] = results_pipeline_q_peak_agreement_bins_guardian\n",
    "\n",
    "results_pipeline_q_peak_agreement_bins_guardian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_output = convert_to_latex(\n",
    "    results_pipeline_q_peak_agreement_bins_guardian.droplevel([1, 2], axis=1),\n",
    "    collapse_index_columns=False,\n",
    "    column_header_bold=True,\n",
    "    column_format=\"p{2.0cm}\"\n",
    "    + \"S[table-column-width=0.75cm,table-format=2.2]\" * len(results_q_peak_agreement_bins_guardian.columns),\n",
    "    caption=r\"Effect of annotation agreement on the absolute error (AE) of selected PEP pipeline [For18, Dro22, None] on the \\textit{Guardian Dataset}, using Q-peak annotations for agreement computation. Annotation agreements: \\textit{high}: [0\\,ms, 4\\,ms], \\textit{medium}: [5\\,ms, 10\\,ms], \\textit{low}: $\\geq$ 11\\,ms.\",\n",
    "    label=\"tab:pipeline_q_peak_annotation_agreement_guardian\",\n",
    ")\n",
    "\n",
    "latex_output = latex_output.replace(\"agreement_bins\", \"Agreement Bins\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries mean\", r\"\\bfseries Mean\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries std\", r\"\\bfseries SD\")\n",
    "latex_output = latex_output.replace(r\"\\sisetup{\", r\"\\sisetup{round-mode=places,round-precision=2,\")\n",
    "\n",
    "suppl_tab_path_paper.joinpath(\"tab_pep_pipeline_q_peak_annotation_agreement_guardian.tex\").open(mode=\"w+\").write(\n",
    "    latex_output\n",
    ")\n",
    "\n",
    "print(latex_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pipeline_b_point_agreement_bins_guardian = add_annotation_agreement_to_results_dataframe(\n",
    "    results_pipeline_guardian, annotations_icg_guardian, dataset_guardian_01.sampling_rate_icg\n",
    ")\n",
    "results_pipeline_b_point_agreement_bins_guardian = results_pipeline_b_point_agreement_bins_guardian.groupby(\n",
    "    \"agreement_bins\", observed=True\n",
    ").agg([\"mean\", \"std\"])\n",
    "result_dict_guardian[\"Annotation_Agreement_Pipeline_B_Point\"] = results_pipeline_b_point_agreement_bins_guardian\n",
    "\n",
    "results_pipeline_b_point_agreement_bins_guardian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_output = convert_to_latex(\n",
    "    results_pipeline_b_point_agreement_bins_guardian.droplevel([1, 2], axis=1),\n",
    "    collapse_index_columns=False,\n",
    "    column_header_bold=True,\n",
    "    column_format=\"p{2.0cm}\"\n",
    "    + \"S[table-column-width=0.75cm,table-format=2.2]\" * len(results_q_peak_agreement_bins_guardian.columns),\n",
    "    caption=r\"Effect of annotation agreement on the absolute error (AE) of selected PEP pipeline [For18, Dro22, None] on the \\textit{Guardian Dataset}, using B-point annotations for agreement computation. Annotation agreements: \\textit{high}: [0\\,ms, 4\\,ms], \\textit{medium}: [5\\,ms, 10\\,ms], \\textit{low}: $\\geq$ 11\\,ms.\",\n",
    "    label=\"tab:pipeline_b_point_annotation_agreement_guardian\",\n",
    ")\n",
    "\n",
    "latex_output = latex_output.replace(\"agreement_bins\", \"Agreement Bins\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries mean\", r\"\\bfseries Mean\")\n",
    "latex_output = latex_output.replace(r\"\\bfseries std\", r\"\\bfseries SD\")\n",
    "latex_output = latex_output.replace(r\"\\sisetup{\", r\"\\sisetup{round-mode=places,round-precision=2,\")\n",
    "\n",
    "suppl_tab_path_paper.joinpath(\"tab_pep_pipeline_b_point_annotation_agreement_guardian.tex\").open(mode=\"w+\").write(\n",
    "    latex_output\n",
    ")\n",
    "\n",
    "print(latex_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between different Agreement Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_q_peak_agreement = pd.concat(\n",
    "    {\n",
    "        \"EmpkinS\": results_q_peak_agreement_bins_empkins.groupby(\"agreement_bins\", observed=True).agg([\"mean\", \"std\"]),\n",
    "        \"Guardian\": results_q_peak_agreement_bins_guardian.groupby(\"agreement_bins\", observed=True).agg(\n",
    "            [\"mean\", \"std\"]\n",
    "        ),\n",
    "    },\n",
    "    axis=0,\n",
    ").dropna(axis=1)\n",
    "\n",
    "results_q_peak_agreement = results_q_peak_agreement.droplevel([1, 2, -1], axis=1)\n",
    "results_q_peak_agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_b_point_agreement = pd.concat(\n",
    "    {\n",
    "        \"EmpkinS\": results_b_point_agreement_bins_empkins.groupby(\"agreement_bins\", observed=True).agg([\"mean\", \"std\"]),\n",
    "        \"Guardian\": results_b_point_agreement_bins_guardian.groupby(\"agreement_bins\", observed=True).agg(\n",
    "            [\"mean\", \"std\"]\n",
    "        ),\n",
    "    },\n",
    "    axis=0,\n",
    ").dropna(axis=1)\n",
    "\n",
    "results_b_point_agreement = results_b_point_agreement.droplevel([1, 2, -1], axis=1)\n",
    "results_b_point_agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "sphinx",
    "format_version": "1.1",
    "jupytext_version": "1.13.0"
   }
  },
  "kernelspec": {
   "display_name": "pepbench",
   "language": "python",
   "name": "pepbench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "7014e6a8beff3a47c7c0424a6c63a486addc0ee3d12468bf1ae9a85a56cca70c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
