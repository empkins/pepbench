{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Analysis on the outputs of the B-Point detection algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The sampling rate of the empkins dataset 1000 Hz does not match the sampling rate of the guardian dataset 500 Hz. How to deal with that? \n",
    "    - Convert to milliseconds. Do it when building the train and test data\n",
    "- Normalize B-Point samples acording to start and end point of heartbeat as part of data preprocessing?\n",
    "    - Try both approaches (This kind of normalization does not make sense)\n",
    "- Start without feature selection since the models should use all outputs generated by the algorithms\n",
    "- How to impute nan values? If normalized between 0 and 1 just use mean?\n",
    "    - drop them first\n",
    "    - Background: Many algorithms don't handle NaN values\n",
    "    - Check how many entries contain NaN\n",
    "    - Use a SimpleImputer with e.g. mean or KNNImputer first to test the pipeline properly (https://scikit-learn.org/1.5/modules/impute.html)\n",
    "- GroupKFold should be used for cross validation to ensure that a participant is not present in the train and testdata\n",
    "- Splitting of the data:\n",
    "    - use biopyskit and apply groupkfold. Mutliindex can remain in dataframe its important, that one hearbeat per row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import biopsykit as bp\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "#Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, RFE\n",
    "\n",
    "#Classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "# Cross-Validation\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from biopsykit.classification.model_selection import SklearnPipelinePermuter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify whether the results should be saved or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('../../results/train_test_data')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(\"../../results/train_test_data\")\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = Path(\"../../results/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv(data_path.joinpath(\"combined_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Requested level (b_point_samplereference) does not match index name (None)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m \u001b[43mbp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_df_sklearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb_point_samplereference\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparticipant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_summary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Development\\ResearchInternship\\Code\\BioPsyKit\\src\\biopsykit\\classification\\utils.py:148\u001b[0m, in \u001b[0;36mprepare_df_sklearn\u001b[1;34m(data, label_col, subject_col, print_summary)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prepare a dataframe for usage in sklearn functions and return the single components of the dataframe.\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03mThis function performs the following steps:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    145\u001b[0m \n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    147\u001b[0m x_data \u001b[38;5;241m=\u001b[39m strip_df(data)\n\u001b[1;32m--> 148\u001b[0m y_data \u001b[38;5;241m=\u001b[39m \u001b[43mstrip_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m groups, group_keys \u001b[38;5;241m=\u001b[39m factorize_subject_id(data, subject_col)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m print_summary:\n",
      "File \u001b[1;32m~\\Development\\ResearchInternship\\Code\\BioPsyKit\\src\\biopsykit\\classification\\utils.py:69\u001b[0m, in \u001b[0;36mstrip_labels\u001b[1;34m(data, label_col)\u001b[0m\n\u001b[0;32m     67\u001b[0m     label_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m---> 69\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(data)\n",
      "File \u001b[1;32mc:\\Users\\sebas\\Development\\ResearchInternship\\Code\\pepbench\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:2127\u001b[0m, in \u001b[0;36mIndex._get_level_values\u001b[1;34m(self, level)\u001b[0m\n\u001b[0;32m   2091\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_level_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, level) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;124;03m    Return an Index of values for requested level.\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2125\u001b[0m \u001b[38;5;124;03m    Index(['a', 'b', 'c'], dtype='object')\u001b[39;00m\n\u001b[0;32m   2126\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2127\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_index_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sebas\\Development\\ResearchInternship\\Code\\pepbench\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:2050\u001b[0m, in \u001b[0;36mIndex._validate_index_level\u001b[1;34m(self, level)\u001b[0m\n\u001b[0;32m   2046\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[0;32m   2047\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many levels: Index has only 1 level, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2048\u001b[0m         )\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m level \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname:\n\u001b[1;32m-> 2050\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m   2051\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested level (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) does not match index name (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2052\u001b[0m     )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Requested level (b_point_samplereference) does not match index name (None)'"
     ]
    }
   ],
   "source": [
    "X, y, groups = bp.classification.utils.prepare_df_sklearn(data=input_data, label_col=\"b_point_samplereference\", subject_col=\"participant\", print_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(data_path.joinpath(\"train_data_all_algos.csv\")).drop(columns=[\"Unnamed: 0\"])\n",
    "target_data = pd.read_csv(data_path.joinpath(\"target_data_all_algos.csv\")).drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Estimator Combinations and Parameters for Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    \"scaler\": {\"StandardScaler\": StandardScaler(), \"MinMaxScaler\": MinMaxScaler()},\n",
    "    #\"reduce_dim\": {\"SelectKBest\": SelectKBest(), \"RFE\": RFE(SVC(kernel=\"linear\", C=1))},\n",
    "    \"reduce_dim\": {\"SelectKBest\": SelectKBest()},\n",
    "    \"clf\": {\n",
    "        #\"KNeighborsRegressor\": KNeighborsRegressor(),\n",
    "        \"RandomForestRegressor\": RandomForestRegressor(),\n",
    "        #\"HistGradientBoostingRegressor\": HistGradientBoostingRegressor(),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\n",
    "    \"StandardScaler\": None,\n",
    "    \"MinMaxScaler\": None,\n",
    "    \"SelectKBest\": {\"k\": [2, 4, 6, 8, 10, \"all\"]},\n",
    "    #\"KNeighborsRegressor\": {\n",
    "    #    \"n_neighbors\": [8,9,10,11,12,13,14],\n",
    "    #    \"weights\": [\"uniform\", \"distance\"],\n",
    "    #    },\n",
    "    \"RandomForestRegressor\": {\n",
    "        #\"n_estimators\": [80, 100, 120],\n",
    "        \"criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"],\n",
    "        #\"min_samples_split\": [1, 2, 3, 4, 5],\n",
    "        #\"min_samples_leaf\": [1, 2, 3, 4, 5],\n",
    "        #\"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    },\n",
    "    #\"HistGradientBoostingRegressor\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper_search_dict = {\"DecisionTreeRegressor\": {\"search_method\": \"random\", \"n_iter\":2}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup PipelinePermuter and Cross-Validations for Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_permuter = SklearnPipelinePermuter(\n",
    "    model_dict=model_dict, param_dict=params_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=[\"participant\", \"condition\", \"phase\", \"heartbeat_idreference\"])\n",
    "y = target_data.drop(columns=[\"participant\", \"condition\", \"phase\", \"heartbeat_idreference\"])\n",
    "groups = train_data[\"participant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63c0e48478242899c0885ff5f7ea0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pipeline Combinations:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Running hyperparameter search for pipeline: (('scaler', 'StandardScaler'), ('reduce_dim', 'SelectKBest'), ('clf', 'RandomForestRegressor')) with 1 parameter grid(s):\n",
      "Parameter grid #0 ({'search_method': 'grid'}): {'clf__criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'], 'reduce_dim__k': [2, 4, 6, 8, 10, 'all']}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9960ff3b64134b088c8756f815ddead5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer CV:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\Development\\ResearchInternship\\Code\\pepbench\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\sebas\\Development\\ResearchInternship\\Code\\BioPsyKit\\src\\biopsykit\\classification\\model_selection\\nested_cv.py:149: UserWarning: Cannot compute confusion matrix for regression tasks.\n",
      "  warnings.warn(\"Cannot compute confusion matrix for regression tasks.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\Development\\ResearchInternship\\Code\\pepbench\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\sebas\\Development\\ResearchInternship\\Code\\BioPsyKit\\src\\biopsykit\\classification\\model_selection\\nested_cv.py:149: UserWarning: Cannot compute confusion matrix for regression tasks.\n",
      "  warnings.warn(\"Cannot compute confusion matrix for regression tasks.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\Development\\ResearchInternship\\Code\\pepbench\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\sebas\\Development\\ResearchInternship\\Code\\BioPsyKit\\src\\biopsykit\\classification\\model_selection\\nested_cv.py:149: UserWarning: Cannot compute confusion matrix for regression tasks.\n",
      "  warnings.warn(\"Cannot compute confusion matrix for regression tasks.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\Development\\ResearchInternship\\Code\\pepbench\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\sebas\\Development\\ResearchInternship\\Code\\BioPsyKit\\src\\biopsykit\\classification\\model_selection\\nested_cv.py:149: UserWarning: Cannot compute confusion matrix for regression tasks.\n",
      "  warnings.warn(\"Cannot compute confusion matrix for regression tasks.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\Development\\ResearchInternship\\Code\\pepbench\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### Running hyperparameter search for pipeline: (('scaler', 'MinMaxScaler'), ('reduce_dim', 'SelectKBest'), ('clf', 'RandomForestRegressor')) with 1 parameter grid(s):\n",
      "Parameter grid #0 ({'search_method': 'grid'}): {'clf__criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'], 'reduce_dim__k': [2, 4, 6, 8, 10, 'all']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\Development\\ResearchInternship\\Code\\BioPsyKit\\src\\biopsykit\\classification\\model_selection\\nested_cv.py:149: UserWarning: Cannot compute confusion matrix for regression tasks.\n",
      "  warnings.warn(\"Cannot compute confusion matrix for regression tasks.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21250c00380433c8a1a20bdb0eb315d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer CV:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\Development\\ResearchInternship\\Code\\pepbench\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\sebas\\Development\\ResearchInternship\\Code\\pepbench\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\sebas\\Development\\ResearchInternship\\Code\\BioPsyKit\\src\\biopsykit\\classification\\model_selection\\nested_cv.py:149: UserWarning: Cannot compute confusion matrix for regression tasks.\n",
      "  warnings.warn(\"Cannot compute confusion matrix for regression tasks.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\Development\\ResearchInternship\\Code\\pepbench\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\sebas\\Development\\ResearchInternship\\Code\\pepbench\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\sebas\\Development\\ResearchInternship\\Code\\BioPsyKit\\src\\biopsykit\\classification\\model_selection\\nested_cv.py:149: UserWarning: Cannot compute confusion matrix for regression tasks.\n",
      "  warnings.warn(\"Cannot compute confusion matrix for regression tasks.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\Development\\ResearchInternship\\Code\\pepbench\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\sebas\\Development\\ResearchInternship\\Code\\pepbench\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\sebas\\Development\\ResearchInternship\\Code\\BioPsyKit\\src\\biopsykit\\classification\\model_selection\\nested_cv.py:149: UserWarning: Cannot compute confusion matrix for regression tasks.\n",
      "  warnings.warn(\"Cannot compute confusion matrix for regression tasks.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\Development\\ResearchInternship\\Code\\pepbench\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\sebas\\Development\\ResearchInternship\\Code\\pepbench\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\sebas\\Development\\ResearchInternship\\Code\\BioPsyKit\\src\\biopsykit\\classification\\model_selection\\nested_cv.py:149: UserWarning: Cannot compute confusion matrix for regression tasks.\n",
      "  warnings.warn(\"Cannot compute confusion matrix for regression tasks.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\Development\\ResearchInternship\\Code\\pepbench\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\sebas\\Development\\ResearchInternship\\Code\\pepbench\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\sebas\\Development\\ResearchInternship\\Code\\BioPsyKit\\src\\biopsykit\\classification\\model_selection\\nested_cv.py:149: UserWarning: Cannot compute confusion matrix for regression tasks.\n",
      "  warnings.warn(\"Cannot compute confusion matrix for regression tasks.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outer_cv = GroupKFold(n_splits=5)\n",
    "inner_cv = GroupKFold(n_splits=5)\n",
    "\n",
    "pipeline_permuter.fit(X=X.values, y=y.values, outer_cv=outer_cv, inner_cv=inner_cv, scoring=\"neg_mean_absolute_error\", groups=groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the resuslts of the pipeline permuter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print the results I had to exclude the conf matrix in the Biopsykit function.  \n",
    "Make sure to include it again afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>true_labels</th>\n",
       "      <th>true_labels_folds</th>\n",
       "      <th>predicted_labels</th>\n",
       "      <th>predicted_labels_folds</th>\n",
       "      <th>train_indices</th>\n",
       "      <th>train_indices_folds</th>\n",
       "      <th>test_indices</th>\n",
       "      <th>test_indices_folds</th>\n",
       "      <th>mean_test_neg_mean_absolute_error</th>\n",
       "      <th>std_test_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_absolute_error_fold_0</th>\n",
       "      <th>test_neg_mean_absolute_error_fold_1</th>\n",
       "      <th>test_neg_mean_absolute_error_fold_2</th>\n",
       "      <th>test_neg_mean_absolute_error_fold_3</th>\n",
       "      <th>test_neg_mean_absolute_error_fold_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pipeline_scaler</th>\n",
       "      <th>pipeline_reduce_dim</th>\n",
       "      <th>pipeline_clf</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>StandardScaler</th>\n",
       "      <th>SelectKBest</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>[[622.0], [1231.0], [3342.0], [4596.0], [5233....</td>\n",
       "      <td>[[[622.0], [1231.0], [3342.0], [4596.0], [5233...</td>\n",
       "      <td>[624.22, 1273.84, 3340.91, 4641.41, 5282.65, 5...</td>\n",
       "      <td>[[624.22, 1273.84, 3340.91, 4641.41, 5282.65, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13...</td>\n",
       "      <td>[1397, 1398, 1399, 1400, 1401, 1402, 1403, 140...</td>\n",
       "      <td>[[1397, 1398, 1399, 1400, 1401, 1402, 1403, 14...</td>\n",
       "      <td>13.735736</td>\n",
       "      <td>0.661483</td>\n",
       "      <td>14.275545</td>\n",
       "      <td>13.314558</td>\n",
       "      <td>14.008832</td>\n",
       "      <td>12.654518</td>\n",
       "      <td>14.425228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinMaxScaler</th>\n",
       "      <th>SelectKBest</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>[[622.0], [1231.0], [3342.0], [4596.0], [5233....</td>\n",
       "      <td>[[[622.0], [1231.0], [3342.0], [4596.0], [5233...</td>\n",
       "      <td>[624.31, 1273.7, 3340.16, 4641.41, 5282.65, 58...</td>\n",
       "      <td>[[624.31, 1273.7, 3340.16, 4641.41, 5282.65, 5...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13...</td>\n",
       "      <td>[1397, 1398, 1399, 1400, 1401, 1402, 1403, 140...</td>\n",
       "      <td>[[1397, 1398, 1399, 1400, 1401, 1402, 1403, 14...</td>\n",
       "      <td>13.723299</td>\n",
       "      <td>0.686075</td>\n",
       "      <td>14.286753</td>\n",
       "      <td>13.276116</td>\n",
       "      <td>14.024607</td>\n",
       "      <td>12.603995</td>\n",
       "      <td>14.425024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 true_labels  \\\n",
       "pipeline_scaler pipeline_reduce_dim pipeline_clf                                                               \n",
       "StandardScaler  SelectKBest         RandomForestRegressor  [[622.0], [1231.0], [3342.0], [4596.0], [5233....   \n",
       "MinMaxScaler    SelectKBest         RandomForestRegressor  [[622.0], [1231.0], [3342.0], [4596.0], [5233....   \n",
       "\n",
       "                                                                                           true_labels_folds  \\\n",
       "pipeline_scaler pipeline_reduce_dim pipeline_clf                                                               \n",
       "StandardScaler  SelectKBest         RandomForestRegressor  [[[622.0], [1231.0], [3342.0], [4596.0], [5233...   \n",
       "MinMaxScaler    SelectKBest         RandomForestRegressor  [[[622.0], [1231.0], [3342.0], [4596.0], [5233...   \n",
       "\n",
       "                                                                                            predicted_labels  \\\n",
       "pipeline_scaler pipeline_reduce_dim pipeline_clf                                                               \n",
       "StandardScaler  SelectKBest         RandomForestRegressor  [624.22, 1273.84, 3340.91, 4641.41, 5282.65, 5...   \n",
       "MinMaxScaler    SelectKBest         RandomForestRegressor  [624.31, 1273.7, 3340.16, 4641.41, 5282.65, 58...   \n",
       "\n",
       "                                                                                      predicted_labels_folds  \\\n",
       "pipeline_scaler pipeline_reduce_dim pipeline_clf                                                               \n",
       "StandardScaler  SelectKBest         RandomForestRegressor  [[624.22, 1273.84, 3340.91, 4641.41, 5282.65, ...   \n",
       "MinMaxScaler    SelectKBest         RandomForestRegressor  [[624.31, 1273.7, 3340.16, 4641.41, 5282.65, 5...   \n",
       "\n",
       "                                                                                               train_indices  \\\n",
       "pipeline_scaler pipeline_reduce_dim pipeline_clf                                                               \n",
       "StandardScaler  SelectKBest         RandomForestRegressor  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "MinMaxScaler    SelectKBest         RandomForestRegressor  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "\n",
       "                                                                                         train_indices_folds  \\\n",
       "pipeline_scaler pipeline_reduce_dim pipeline_clf                                                               \n",
       "StandardScaler  SelectKBest         RandomForestRegressor  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13...   \n",
       "MinMaxScaler    SelectKBest         RandomForestRegressor  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13...   \n",
       "\n",
       "                                                                                                test_indices  \\\n",
       "pipeline_scaler pipeline_reduce_dim pipeline_clf                                                               \n",
       "StandardScaler  SelectKBest         RandomForestRegressor  [1397, 1398, 1399, 1400, 1401, 1402, 1403, 140...   \n",
       "MinMaxScaler    SelectKBest         RandomForestRegressor  [1397, 1398, 1399, 1400, 1401, 1402, 1403, 140...   \n",
       "\n",
       "                                                                                          test_indices_folds  \\\n",
       "pipeline_scaler pipeline_reduce_dim pipeline_clf                                                               \n",
       "StandardScaler  SelectKBest         RandomForestRegressor  [[1397, 1398, 1399, 1400, 1401, 1402, 1403, 14...   \n",
       "MinMaxScaler    SelectKBest         RandomForestRegressor  [[1397, 1398, 1399, 1400, 1401, 1402, 1403, 14...   \n",
       "\n",
       "                                                           mean_test_neg_mean_absolute_error  \\\n",
       "pipeline_scaler pipeline_reduce_dim pipeline_clf                                               \n",
       "StandardScaler  SelectKBest         RandomForestRegressor                          13.735736   \n",
       "MinMaxScaler    SelectKBest         RandomForestRegressor                          13.723299   \n",
       "\n",
       "                                                           std_test_neg_mean_absolute_error  \\\n",
       "pipeline_scaler pipeline_reduce_dim pipeline_clf                                              \n",
       "StandardScaler  SelectKBest         RandomForestRegressor                          0.661483   \n",
       "MinMaxScaler    SelectKBest         RandomForestRegressor                          0.686075   \n",
       "\n",
       "                                                           test_neg_mean_absolute_error_fold_0  \\\n",
       "pipeline_scaler pipeline_reduce_dim pipeline_clf                                                 \n",
       "StandardScaler  SelectKBest         RandomForestRegressor                            14.275545   \n",
       "MinMaxScaler    SelectKBest         RandomForestRegressor                            14.286753   \n",
       "\n",
       "                                                           test_neg_mean_absolute_error_fold_1  \\\n",
       "pipeline_scaler pipeline_reduce_dim pipeline_clf                                                 \n",
       "StandardScaler  SelectKBest         RandomForestRegressor                            13.314558   \n",
       "MinMaxScaler    SelectKBest         RandomForestRegressor                            13.276116   \n",
       "\n",
       "                                                           test_neg_mean_absolute_error_fold_2  \\\n",
       "pipeline_scaler pipeline_reduce_dim pipeline_clf                                                 \n",
       "StandardScaler  SelectKBest         RandomForestRegressor                            14.008832   \n",
       "MinMaxScaler    SelectKBest         RandomForestRegressor                            14.024607   \n",
       "\n",
       "                                                           test_neg_mean_absolute_error_fold_3  \\\n",
       "pipeline_scaler pipeline_reduce_dim pipeline_clf                                                 \n",
       "StandardScaler  SelectKBest         RandomForestRegressor                            12.654518   \n",
       "MinMaxScaler    SelectKBest         RandomForestRegressor                            12.603995   \n",
       "\n",
       "                                                           test_neg_mean_absolute_error_fold_4  \n",
       "pipeline_scaler pipeline_reduce_dim pipeline_clf                                                \n",
       "StandardScaler  SelectKBest         RandomForestRegressor                            14.425228  \n",
       "MinMaxScaler    SelectKBest         RandomForestRegressor                            14.425024  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_permuter.metric_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\Development\\ResearchInternship\\Code\\BioPsyKit\\src\\biopsykit\\classification\\model_selection\\sklearn_pipeline_permuter.py:680: FutureWarning: ['param_clf__criterion', 'param_reduce_dim__k', 'params'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
      "  .agg([\"mean\", \"std\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_neg_mean_absolute_error</th>\n",
       "      <th>param_clf__criterion</th>\n",
       "      <th>param_reduce_dim__k</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_neg_mean_absolute_error</th>\n",
       "      <th>split0_test_neg_mean_absolute_error</th>\n",
       "      <th>split1_test_neg_mean_absolute_error</th>\n",
       "      <th>split2_test_neg_mean_absolute_error</th>\n",
       "      <th>split3_test_neg_mean_absolute_error</th>\n",
       "      <th>split4_test_neg_mean_absolute_error</th>\n",
       "      <th>std_test_neg_mean_absolute_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outer_fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-13.697996</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>4</td>\n",
       "      <td>{'clf__criterion': 'absolute_error', 'reduce_d...</td>\n",
       "      <td>2</td>\n",
       "      <td>-13.787161</td>\n",
       "      <td>-14.243101</td>\n",
       "      <td>-13.618856</td>\n",
       "      <td>-13.241658</td>\n",
       "      <td>-13.599204</td>\n",
       "      <td>0.325379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-13.957128</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>4</td>\n",
       "      <td>{'clf__criterion': 'absolute_error', 'reduce_d...</td>\n",
       "      <td>2</td>\n",
       "      <td>-13.457105</td>\n",
       "      <td>-13.638498</td>\n",
       "      <td>-13.554444</td>\n",
       "      <td>-14.539383</td>\n",
       "      <td>-14.596208</td>\n",
       "      <td>0.502224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13.730262</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>4</td>\n",
       "      <td>{'clf__criterion': 'absolute_error', 'reduce_d...</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.451196</td>\n",
       "      <td>-14.598374</td>\n",
       "      <td>-13.303103</td>\n",
       "      <td>-13.980553</td>\n",
       "      <td>-13.318086</td>\n",
       "      <td>0.499298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-14.304568</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>4</td>\n",
       "      <td>{'clf__criterion': 'absolute_error', 'reduce_d...</td>\n",
       "      <td>1</td>\n",
       "      <td>-14.152876</td>\n",
       "      <td>-14.361676</td>\n",
       "      <td>-14.103827</td>\n",
       "      <td>-14.158255</td>\n",
       "      <td>-14.746205</td>\n",
       "      <td>0.237916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-13.930380</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>4</td>\n",
       "      <td>{'clf__criterion': 'absolute_error', 'reduce_d...</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.213718</td>\n",
       "      <td>-12.648656</td>\n",
       "      <td>-14.886735</td>\n",
       "      <td>-15.116419</td>\n",
       "      <td>-13.786372</td>\n",
       "      <td>0.948521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean_test_neg_mean_absolute_error param_clf__criterion  \\\n",
       "outer_fold                                                           \n",
       "0                                  -13.697996       absolute_error   \n",
       "1                                  -13.957128       absolute_error   \n",
       "2                                  -13.730262       absolute_error   \n",
       "3                                  -14.304568       absolute_error   \n",
       "4                                  -13.930380       absolute_error   \n",
       "\n",
       "           param_reduce_dim__k  \\\n",
       "outer_fold                       \n",
       "0                            4   \n",
       "1                            4   \n",
       "2                            4   \n",
       "3                            4   \n",
       "4                            4   \n",
       "\n",
       "                                                       params  \\\n",
       "outer_fold                                                      \n",
       "0           {'clf__criterion': 'absolute_error', 'reduce_d...   \n",
       "1           {'clf__criterion': 'absolute_error', 'reduce_d...   \n",
       "2           {'clf__criterion': 'absolute_error', 'reduce_d...   \n",
       "3           {'clf__criterion': 'absolute_error', 'reduce_d...   \n",
       "4           {'clf__criterion': 'absolute_error', 'reduce_d...   \n",
       "\n",
       "            rank_test_neg_mean_absolute_error  \\\n",
       "outer_fold                                      \n",
       "0                                           2   \n",
       "1                                           2   \n",
       "2                                           1   \n",
       "3                                           1   \n",
       "4                                           1   \n",
       "\n",
       "            split0_test_neg_mean_absolute_error  \\\n",
       "outer_fold                                        \n",
       "0                                    -13.787161   \n",
       "1                                    -13.457105   \n",
       "2                                    -13.451196   \n",
       "3                                    -14.152876   \n",
       "4                                    -13.213718   \n",
       "\n",
       "            split1_test_neg_mean_absolute_error  \\\n",
       "outer_fold                                        \n",
       "0                                    -14.243101   \n",
       "1                                    -13.638498   \n",
       "2                                    -14.598374   \n",
       "3                                    -14.361676   \n",
       "4                                    -12.648656   \n",
       "\n",
       "            split2_test_neg_mean_absolute_error  \\\n",
       "outer_fold                                        \n",
       "0                                    -13.618856   \n",
       "1                                    -13.554444   \n",
       "2                                    -13.303103   \n",
       "3                                    -14.103827   \n",
       "4                                    -14.886735   \n",
       "\n",
       "            split3_test_neg_mean_absolute_error  \\\n",
       "outer_fold                                        \n",
       "0                                    -13.241658   \n",
       "1                                    -14.539383   \n",
       "2                                    -13.980553   \n",
       "3                                    -14.158255   \n",
       "4                                    -15.116419   \n",
       "\n",
       "            split4_test_neg_mean_absolute_error  \\\n",
       "outer_fold                                        \n",
       "0                                    -13.599204   \n",
       "1                                    -14.596208   \n",
       "2                                    -13.318086   \n",
       "3                                    -14.746205   \n",
       "4                                    -13.786372   \n",
       "\n",
       "            std_test_neg_mean_absolute_error  \n",
       "outer_fold                                    \n",
       "0                                   0.325379  \n",
       "1                                   0.502224  \n",
       "2                                   0.499298  \n",
       "3                                   0.237916  \n",
       "4                                   0.948521  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_permuter.best_hyperparameter_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results of the pipeline permuter to a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_results:\n",
    "    pipeline_permuter.to_pickle(models_path.joinpath(\"Scaler_Feature_Elimination_Random_Forest.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
