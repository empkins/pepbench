{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# PEP Benchmarking - Guardian Dataset Both Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook executes the PEP Benchmarking challenges on the Guardian Dataset for PEP Extraction Pipelines using automated algorithms for both Q-wave onset and B-point extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from fau_colors import cmaps, register_fausans_font\n",
    "from IPython.display import Markdown\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pepbench.algorithms.ecg import (\n",
    "    QPeakExtractionForounzafar2018,\n",
    "    QPeakExtractionMartinez2004Neurokit,\n",
    "    QPeakExtractionSciPyFindPeaksNeurokit,\n",
    "    QPeakExtractionVanLien2013,\n",
    ")\n",
    "from pepbench.algorithms.heartbeat_segmentation import HeartbeatSegmentationNeurokit\n",
    "from pepbench.algorithms.icg import (\n",
    "    BPointExtractionArbol2017IsoelectricCrossings,\n",
    "    BPointExtractionArbol2017SecondDerivative,\n",
    "    BPointExtractionArbol2017ThirdDerivative,\n",
    "    BPointExtractionDebski1993SecondDerivative,\n",
    "    BPointExtractionDrost2022,\n",
    "    BPointExtractionForouzanfar2018,\n",
    "    BPointExtractionLozano2007LinearRegression,\n",
    "    BPointExtractionLozano2007QuadraticRegression,\n",
    "    BPointExtractionSherwood1990,\n",
    "    BPointExtractionStern1985,\n",
    ")\n",
    "from pepbench.algorithms.outlier_correction import (\n",
    "    OutlierCorrectionDummy,\n",
    "    OutlierCorrectionForouzanfar2018,\n",
    "    OutlierCorrectionLinearInterpolation,\n",
    ")\n",
    "from pepbench.datasets import GuardianDataset\n",
    "from pepbench.evaluation import PepEvaluationChallenge\n",
    "from pepbench.pipelines import PepExtractionPipeline\n",
    "\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_fausans_font()\n",
    "plt.close(\"all\")\n",
    "\n",
    "palette = sns.color_palette(cmaps.faculties)\n",
    "sns.set_theme(context=\"notebook\", style=\"ticks\", font=\"sans-serif\", palette=palette)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42\n",
    "plt.rcParams[\"mathtext.default\"] = \"regular\"\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams[\"font.sans-serif\"] = \"FAUSans Office\"\n",
    "\n",
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_type = \"local\"\n",
    "\n",
    "config_dict = json.load(root_path.joinpath(\"config.json\").open(encoding=\"utf-8\"))\n",
    "\n",
    "guardian_base_path = Path(config_dict[deploy_type][\"guardian_path\"])\n",
    "print(guardian_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = root_path.joinpath(\"results/guardian_dataset_both_algorithms\")\n",
    "result_path.mkdir(exist_ok=True, parents=True)\n",
    "result_path.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_guardian = GuardianDataset(guardian_base_path, use_cache=True, only_labeled=True)\n",
    "dataset_guardian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heartbeat Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartbeat_segmentation_algo = HeartbeatSegmentationNeurokit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECG - Q-Wave Onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_wave_algo_dict = {\n",
    "    \"martinez2004\": QPeakExtractionMartinez2004Neurokit(),\n",
    "    \"forounzafar2018\": QPeakExtractionForounzafar2018(),\n",
    "    \"scipy-findpeaks\": QPeakExtractionSciPyFindPeaksNeurokit(),\n",
    "}\n",
    "q_wave_algo_dict.update(\n",
    "    **{f\"vanlien2013-{i}-ms\": QPeakExtractionVanLien2013(time_interval_ms=i) for i in np.arange(32, 44, 2)}\n",
    ")\n",
    "q_wave_algos = list(q_wave_algo_dict.items())\n",
    "\n",
    "print(\"Available Q-wave Onset algorithms:\")\n",
    "pprint(q_wave_algo_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICG - B-Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_point_algo_dict = {\n",
    "    \"stern1985\": BPointExtractionStern1985(),\n",
    "    \"sherwood1990\": BPointExtractionSherwood1990(),\n",
    "    \"debski1993-second-derivative\": BPointExtractionDebski1993SecondDerivative(),\n",
    "    \"lozano2007-linear-regression\": BPointExtractionLozano2007LinearRegression(),\n",
    "    \"lozano2007-quadratic-regression\": BPointExtractionLozano2007QuadraticRegression(),\n",
    "    \"arbol2017-isoelectric-crossings\": BPointExtractionArbol2017IsoelectricCrossings(),\n",
    "    \"arbol2017-second-derivative\": BPointExtractionArbol2017SecondDerivative(),\n",
    "    \"arbol2017-third-derivative\": BPointExtractionArbol2017ThirdDerivative(),\n",
    "    \"forounzafar2018\": BPointExtractionForouzanfar2018(),\n",
    "    \"drost2022\": BPointExtractionDrost2022(),\n",
    "}\n",
    "b_point_algos = list(b_point_algo_dict.items())\n",
    "\n",
    "print(\"Available B-point algorithms:\")\n",
    "pprint(b_point_algo_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_correction_dict = {\n",
    "    \"none\": OutlierCorrectionDummy(),\n",
    "    \"linear-interpolation\": OutlierCorrectionLinearInterpolation(),\n",
    "    \"forouzanfar2018\": OutlierCorrectionForouzanfar2018(),\n",
    "}\n",
    "outlier_correction_algos = list(outlier_correction_dict.items())\n",
    "\n",
    "print(\"Available Outlier Correction algorithms:\")\n",
    "pprint(outlier_correction_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_combinations = list(product(q_wave_algos, b_point_algos, outlier_correction_algos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_result_dict = {}\n",
    "\n",
    "for algo_combi in tqdm(algo_combinations):\n",
    "    algo_combi_names = [key[0] for key in algo_combi]\n",
    "\n",
    "    filename_stub = \"pep_results_guardian_\" + \"_\".join(algo_combi_names)\n",
    "\n",
    "    # check if exists\n",
    "    if len(list(result_path.glob(f\"{filename_stub}*\"))) != 0:\n",
    "        display(Markdown(f\"Algrotihm combination {algo_combi_names} already challenged. Skipping...\"))\n",
    "        continue\n",
    "\n",
    "    display(Markdown(f\"Running algorithm combination {algo_combi_names}\"))\n",
    "    pep_challenge = PepEvaluationChallenge(dataset=dataset_guardian, validate_kwargs={\"n_jobs\": -1})\n",
    "\n",
    "    pipeline = PepExtractionPipeline(\n",
    "        heartbeat_segmentation_algo=heartbeat_segmentation_algo,\n",
    "        q_wave_algo=algo_combi[0][1],\n",
    "        b_point_algo=algo_combi[1][1],\n",
    "        outlier_correction_algo=algo_combi[2][1],\n",
    "        handle_negative_pep=\"nan\",\n",
    "        handle_missing_events=\"ignore\",\n",
    "    )\n",
    "    pep_challenge.run(pipeline)\n",
    "    pep_challenge.results_as_df()\n",
    "    pep_challenge.save_results(result_path, filename_stub)\n",
    "\n",
    "    big_result_dict[tuple(algo_combi_names)] = pep_challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "sphinx",
    "format_version": "1.1",
    "jupytext_version": "1.13.0"
   }
  },
  "kernelspec": {
   "display_name": "pepbench",
   "language": "python",
   "name": "pepbench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "7014e6a8beff3a47c7c0424a6c63a486addc0ee3d12468bf1ae9a85a56cca70c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
